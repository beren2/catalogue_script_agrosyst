{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de l'API Datagrosyst (Python)\n",
    "\n",
    "Le but de ce code est d'utiliser l'API de Datagrosyst afin de g√©n√©rer une requ√®te de t√©l√©chargement des tables que vous indiquerez au pr√©alable. Celui-ci va permettre de recevoir le mail avec le lien Filesender de t√©l√©chargement. L'√©tape de t√©l√©chargement via le filesender n'est pas automatiser, il faudra aller manuellement dans votre boite et mail, cliquer sur le lien et t√©l√©charger.\n",
    "\n",
    "Nous allons √©galement vous faire une code qui ira chercher dans votre dossier de t√©l√©chargement le fichier Filesender, pour le d√©compr√©ss√© et le stocker dans un autre dossier (votre dossier de travail).\n",
    "\n",
    "Ensuite, un dernier bout de code afin d'importer les tables que vous venez de t√©l√©charger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation de la requ√®te et des chemins de dossier\n",
    "\n",
    "<font color=\"#900000\">Attention</font>  aux noms des tables !  \n",
    "Les cha√Ænes de caract√®res permettant d‚Äôidentifier les tables dans le champ **\"tables\"** sont celles qui sont disponibles dans le volet √† droite sur Datagrosyst. Celles-ci diff√®rent parfois du nom disponible sur l‚Äôinterface de s√©lection. Par exemple, dans le magasin_can, lorsqu‚Äôon s√©lectionne *‚Äúdomaine‚Äù*, on voit appara√Ætre √† droite *‚Äúdomaine_magasin_can‚Äù*. C‚Äôest ce dernier libell√© qu‚Äôil faut saisir dans le champ **\"tables\"** pour obtenir table domaine du magasin_can, car saisir simplement *‚Äúdomaine‚Äù* ferait r√©f√©rence √† la table domaine de l‚Äôentrep√¥t.\n",
    "\n",
    "\n",
    "<font color=\"#900000\">Attention</font> aux restrictions d'acc√®s aux donn√©es !  \n",
    "Si vous saisissez dans **‚Äútables‚Äù** des noms de tables pour lesquelles vous n‚Äôavez pas les droits, celles-ci ne seront pas ajout√©es dans l‚Äôexport obtenu.\n",
    "\n",
    "Le <font color=\"green\">token de l'API</font> est en quelque sorte un mot de passe, ne pas le transmettre !  \n",
    "Vous le trouverez dans [üîó votre profil](https://agrosyst.fr/datagrosyst/profil) sur Datagrosyst, au dessus des param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://agrosyst.fr/datagrosyst/export'\n",
    "\n",
    "url = 'https://agrosyst.fr/datagrosyst-tests/export'\n",
    "\n",
    "# La liste des tables √† r√©cup√©rer\n",
    "tables = [\"domaine\",'parcelle'] # A modifier\n",
    "\n",
    "# La strucuture de la requ√®te\n",
    "# Modifier \"mail\" et \"token\" avec vos informations personnelles disponibles dans le profil de votre compte Datagrosyst\n",
    "data_request = {\n",
    "    \"mail\": \"votreadressemail@exemple.fr\",      # A modifier\n",
    "    \"token\": \"tokendiponiblesurDatagrosyst\",    # A modifier\n",
    "    \"tables\": tables           \n",
    "}\n",
    "\n",
    "data_request = {\n",
    "    \"mail\": \"thomas.badie@inrae.fr\",\n",
    "    \"token\": \"d94bba29-3431-4442-a589-b5d2d6b9cd5b\",\n",
    "    \"tables\": tables\n",
    "}\n",
    "\n",
    "# Les chemins vers vos dossiers locaux\n",
    "path_download = \"/chemin/vers/ton/dossier/de/T√©l√©chargements\"       # Modifier ici le chemin vers ton dossier de t√©l√©chargements\n",
    "path_workdirectory = \"/chemin/vers/ton/Workdirectory\"               # Modifier ici le chemin vers ton dossier de travail\n",
    "\n",
    "path_download = \"/home/administrateur/T√©l√©chargements\"\n",
    "path_workdirectory = \"/home/administrateur/Bureau/testtest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Envoy√© la demande √† Datagrosyst grace √† 'requests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envoi de la requ√™te POST √† l'API Datagrosyst\n",
    "response = requests.post(url, json=data_request)\n",
    "\n",
    "# Code de v√©rification de la r√©ponse de l'API\n",
    "if response.status_code == 200:\n",
    "    print(\"Requ√™te r√©ussie !\")\n",
    "else:\n",
    "    print(f\"Erreur lors de la requ√™te. Code d'√©tat : {response.status_code}\")\n",
    "    print(\"R√©ponse :\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T√©l√©charger les donn√©es\n",
    "\n",
    "**<font color=\"#900000\">Attention cette √©tape est manuelle !</font>**  \n",
    "Vous aller recevoir un mail de la part de Filesender vous invitant √† aller t√©l√©charger les donn√©es stock√©es pour vous via un lien. Cliquez sur ce lien, puis t√©l√©charger le fichier compr√©ss√©. Ce fichier va noramlement se retrouver directement dans votre dossier de t√©l√©chargement **path_download**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©placer et d√©compr√©ss√© le fichier Filesender t√©l√©charg√©\n",
    "\n",
    "Vous avez d√©sormais le fichier compr√©ss√© dans votre dossier de t√©l√©chargement. Avec le code propos√© ci-dessous, vous aller en plusieurs √©tapes : \n",
    "- **Trouver le fichier .tar.gz** (extension des fichiers compr√©ss√©s) *le plus r√©cent* de votre dossier de t√©l√©chargement\n",
    "- **Copier** ce fichier vers votre dossier de travail\n",
    "- **D√©compr√©ss√©** le fichier, ce qui va automatiquement √©craser les anciennes tables pour mettre les nouvelles tables (celles pr√©sentes dans le fichier compr√©ss√©, que vous avez d√©fini lors de l'initialisation)\n",
    "- **Supprim√©** le fichier compr√©ss√© pour ne gard√© que les tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier le plus r√©cent : /home/administrateur/T√©l√©chargements/export_525e41b7-6cbd-45a6-94fe-abc8947546f7.tar.gz\n",
      "D√©compression termin√©e dans /home/administrateur/Bureau/testtest.\n"
     ]
    }
   ],
   "source": [
    "# Trouver le fichier .tar.gz le plus r√©cent du dossier de t√©l√©chargements\n",
    "tar_files = [f for f in os.listdir(path_download) if f.endswith('.tar.gz')]\n",
    "if not tar_files:\n",
    "    raise FileNotFoundError(\"Aucun fichier .tar.gz trouv√©.\")\n",
    "\n",
    "latest_file = max(\n",
    "    [os.path.join(path_download, f) for f in tar_files],\n",
    "    key=os.path.getmtime\n",
    ")\n",
    "print(f\"Fichier le plus r√©cent : {latest_file}\")\n",
    "\n",
    "# Copier le fichier compr√©ss√© vers le dossier de travail\n",
    "os.makedirs(path_workdirectory, exist_ok=True)\n",
    "dest_tar_path = os.path.join(path_workdirectory, os.path.basename(latest_file))\n",
    "\n",
    "with open(latest_file, 'rb') as src, open(dest_tar_path, 'wb') as dst:\n",
    "    dst.write(src.read())\n",
    "\n",
    "# D√©compresser (√©crase automatiquement les fichiers existants, c√†d les plus anciens)\n",
    "with tarfile.open(dest_tar_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=path_workdirectory, filter=\"data\")\n",
    "\n",
    "# Supprime le fichier compress√© dans le dossier de travail apr√®s d√©compression\n",
    "os.remove(dest_tar_path) \n",
    "\n",
    "# Fin\n",
    "print(f\"D√©compression termin√©e dans {path_workdirectory}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es dans le Notebook\n",
    "\n",
    "Vous voici avec les tables de donn√©es nouvellement acquise dans votre dossier de travail !  \n",
    "Maintenant nous allons les importer dans le Notebook. Pour cela nous allons d√©finir un dictionnaire de table dont le nom sera le nom du fichier. Nous pr√©parons aussi une fonction d'import d'une table qui sera reprise par la fonction d'import de plusieurs tables. Nous utilisons ensuite cette derni√®re fonction en sp√©cifiant les **tables** que vous venez de t√©l√©charg√©es (pas toutes celle du dossier de travail !) et le chemin vers le dossier de travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\"domaine\",'nuisible_edi'] # A modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- domaine ---\n",
      "Lignes: 31431, Colonnes: 78 \n",
      "\n",
      "['id', 'nom', 'contact_principal', 'code', 'siret', 'campagne', 'type_ferme', 'departement', 'commune', 'petite_region_agricole', 'commune_id', 'zonage', 'station_meteo_defaut', 'pct_sau_zone_vulnerable', 'pct_sau_zone_actions_complementaires', 'pct_sau_zone_natura_2000', 'pct_sau_zone_erosion', 'pct_sau_zone_excedent_structurel', 'pct_sau_perimetre_protection_captage', 'description', 'statut_juridique_nom', 'statut_juridique_commentaire', 'sau_totale', 'annee_naissance_exploitant', 'cultures_commentaire', 'autres_activites_commentaire', 'mo_commentaire', 'nombre_associes', 'mo_familiale_et_associes', 'mo_permanente', 'mo_temporaire', 'mo_familiale_remuneration', 'charges_salariales', 'mo_conduite_cultures_dans_domaine_expe', 'cotisation_msa', 'fermage_moyen', 'aides_decouplees', 'otex_18_nom', 'otex_70_nom', 'otex_commentaire', 'responsables_domaine', 'nombre_parcelles', 'distance_siege_parcelle_max', 'surface_autour_siege_exploitation', 'parcelles_groupees', 'parcelles_plutot_groupees', 'parcelles_plutot_dispersees', 'parcelles_dispersees', 'parcelles_groupees_distinctes', 'objectifs', 'atouts_domaine', 'contraintes_domaine', 'perspective_evolution_domaine', 'membre_cooperative', 'membre_groupe_developpement', 'membre_cuma', 'domaine_touristique', 'main_oeuvre_exploitant', 'main_oeuvre_non_saisoniere', 'main_oeuvre_saisoniere', 'main_oeuvre_volontaire', 'surface_agricole_utilisee_fermage', 'surface_agricole_experimentale', 'surface_agricole_experimentale_homogeneisation', 'surface_irrigable', 'surface_jachere', 'surface_culture_annuelle', 'surface_vignoble_verger', 'surface_prairie', 'surface_toujours_prairie', 'surface_prairie_autre', 'surface_prairie_uniquement_paturee', 'surface_prairie_uniquement_fauchee', 'surface_collective_landes_parcours', 'surface_landes_parcours', 'surface_paturage_ete_montagne', 'surface_collective_paturage_ete_montagne', 'total_surface_autre'] \n",
      "\n",
      "\n",
      "--- nuisible_edi ---\n",
      "Lignes: 2043, Colonnes: 5 \n",
      "\n",
      "['id', 'categorie_nuisible', 'label_nuisible', 'source', 'reference_id'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation du dictionnaire des dataframes\n",
    "df = {}\n",
    "\n",
    "# D√©finition des fonctions d'importation\n",
    "def import_df(df_name, path_data, sep, index_col=None):\n",
    "    df[df_name] = pd.read_csv(path_data+'/'+df_name+'.csv', sep = sep, index_col=index_col, low_memory=False).replace({'\\r\\n': '\\n'}, regex=True)\n",
    "\n",
    "def import_dfs(df_names, path_data, sep = ',', index_col=None, verbose=False):\n",
    "    for df_name in tqdm(df_names) : \n",
    "        if(verbose) :\n",
    "            print(\" - \", df_name)\n",
    "        import_df(df_name, path_data, sep, index_col=index_col)\n",
    "\n",
    "# Import des donn√©es que vous venez de t√©l√©charger et placer dans le dossier de travail\n",
    "import_dfs(tables, path_workdirectory, sep = ',', verbose=False)\n",
    "\n",
    "# Voir un r√©sum√© du contenu du dictionnaire des premiers dataframes\n",
    "for i, (name, dataframe) in enumerate(df.items()):\n",
    "    if i < 5:  # Limite aux 5 premi√®res tables\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        print(f\"Lignes: {dataframe.shape[0]}, Colonnes: {dataframe.shape[1]}\",\"\\n\")\n",
    "        print(dataframe.columns.tolist(), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogue_script_agrosyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
