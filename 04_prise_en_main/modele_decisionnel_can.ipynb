{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrôle des modèles décisionnels\n",
    "\n",
    "Ce document a pour objectif de fournir des fichiers servant de base au contrôle de la complétude des modèles décisionnels (MD). \n",
    "\n",
    "Comme indiqué ci-dessous, plusieurs informations seront compilées à différentes échelles : \n",
    "- le nombre de cultures déclarées dans les leviers du MD\n",
    "- le nombre de leviers total déclarés dans les rubriques du MD\n",
    "- le nombre de catégories d'objectifs dans les rubriques du MD\n",
    "- le nombre de levier par type de rubrique dans le MD\n",
    "\n",
    "<img src=\"images/suggestion_diagramme.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bvuittenez/anaconda3/envs/agrosyst_entrepot/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ #\n",
    "# IMPORT DES DONNÉES #\n",
    "# ------------------ #\n",
    "ENTREPOT_PATH = '~/Bureau/utils/data/'\n",
    "df = {}\n",
    "\n",
    "def import_df(df_name, path_data, sep, index_col=None):\n",
    "    df[df_name] = pd.read_csv(path_data+df_name+'.csv', sep = sep, index_col=index_col, low_memory=False).replace({'\\r\\n': '\\n'}, regex=True)\n",
    "\n",
    "def import_dfs(df_names, path_data, sep = ',', index_col=None, verbose=False):\n",
    "    for df_name in tqdm(df_names) : \n",
    "        if(verbose) :\n",
    "            print(\" - \", df_name)\n",
    "        import_df(df_name, path_data, sep, index_col=index_col)\n",
    "\n",
    "tables_with_id = [\n",
    "    'modele_decisionnel', \n",
    "    'modele_decisionnel_maitrise', \n",
    "    'modele_decisionnel_strategie',\n",
    "]\n",
    "\n",
    "tables_without_id = [\n",
    "    'modele_decisionnel_strategie_culture'\n",
    "]\n",
    "\n",
    "# import des données de l'entrepôt avec la colonne 'id' en index \n",
    "import_dfs(tables_with_id, ENTREPOT_PATH, sep = ',', index_col='id', verbose=False)\n",
    "\n",
    "# import des données du magasin\n",
    "import_dfs(tables_without_id, ENTREPOT_PATH, sep = ',', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution de modele_decisionnel_strategie_extanded\n",
    "- ajout du nombre de cultures uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptage du nombre de cultures différentes par stratégie :\n",
    "df['modele_decisionnel_strategie_culture_count'] = df['modele_decisionnel_strategie_culture'].groupby('modele_decisionnel_strategie_id').agg({\n",
    "    'culture_id' : pd.Series.nunique\n",
    "}).rename(columns={'culture_id' : 'culture_count'}).fillna(0)\n",
    "\n",
    "# NOTE : si on veut avoir la liste précise des culture utilisées pour pouvoir compter les \"uniques\" lors de futures agrégations, \n",
    "# on peut remplacer \"pd.Series.nunique\" par \"pd.Series.unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire remonter l'information jusqu'au modele_decisionnel_strategie\n",
    "left = df['modele_decisionnel_strategie']\n",
    "right = df['modele_decisionnel_strategie_culture_count']\n",
    "df['modele_decisionnel_strategie_extanded'] = pd.merge(left, right, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution de modele_decisionnel_maitrise_extanded\n",
    "- ajout du nombre de leviers uniques\n",
    "- ajout du nombre de cultures totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptage du nombre de leviers différents par rubrique de maîtrises et somme du nombre de cultures\n",
    "df['modele_decisionnel_maitrise_indicators_count'] = df['modele_decisionnel_strategie_extanded'].groupby('modele_decisionnel_maitrise_id').agg({\n",
    "    'levier' : pd.Series.nunique,\n",
    "    'culture_count' : 'sum' \n",
    "}).rename(columns={'levier' : 'levier_count'}).fillna(0)\n",
    "\n",
    "# NOTE : si on veut avoir la liste précise des leviers pour pouvoir compter les \"uniques\" lors de futures agrégations, \n",
    "# on peut remplacer \"pd.Series.nunique\" par \"pd.Series.unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire remonter l'information jusqu'au modele_decisionnel_maitrise\n",
    "left = df['modele_decisionnel_maitrise']\n",
    "right = df['modele_decisionnel_maitrise_indicators_count']\n",
    "df['modele_decisionnel_maitrise_extanded'] = pd.merge(left, right, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution de modele_decisionnel_extanded\n",
    "- ajout du nombre de rubriques remplies\n",
    "- ajout du nombre de leviers par rubriques\n",
    "- ajout du nombre de leviers total\n",
    "- ajout du nombre de catégories d'objectifs\n",
    "- ajout du nombre de cultures totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition d'un dictionnaire de renommage pour plus de clarté par la suite\n",
    "DICT_RENOMMAGE = {\n",
    "    'ADVENTICES' : 'levier_ADVENTICE_count',\n",
    "    'CYCLE_PLURIANNUEL_DE_CULTURE' : 'levier_CYCLE_PLURIANNUEL_DE_CULTURE_count',\n",
    "    'FERTILITE_SOL_CULTURES' : 'levier_FERTILITE_SOL_CULTURES_count',\n",
    "    'MAITRISE_DES_DOMMAGES_PHYSIQUES' : 'levier_MAITRISE_DES_DOMMAGES_PHYSIQUES_count',\n",
    "    'MALADIES' : 'levier_MALADIES_count',\n",
    "    'PRODUCTION' : 'levier_PRODUCTION_count',\n",
    "    'RAVAGEURS' : 'levier_RAVAGEURS_count',\n",
    "    'TRAVAIL_DU_SOL' : 'levier_TRAVAIL_DU_SOL_count'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptage du nombre de leviers par type de rubrique pour chaque modèle décisionnel.\n",
    "df['modele_decisionnel_leviers_count'] = df['modele_decisionnel_maitrise_extanded'].reset_index().groupby(['modele_decisionnel_id', 'type_rubrique']).agg({\n",
    "    'levier_count' : 'sum'\n",
    "}).rename(columns={'id' : 'rubrique_count', 'categorie_objectif' : 'categorie_objectif_count'}).fillna(0)\n",
    "\n",
    "# pivot de la table pour obtenir une colonne par type de rubrique (voir le fonctionnement de pivot : https://pandas.pydata.org/docs/user_guide/reshaping.html)\n",
    "df['modele_decisionnel_type_rubrique_count'] = df['modele_decisionnel_leviers_count'].reset_index().pivot(\n",
    "    index='modele_decisionnel_id', \n",
    "    columns='type_rubrique',\n",
    "    values='levier_count'\n",
    ").fillna(0)\n",
    "\n",
    "# comptage du nombre de rubriques pour chaque modèle décisionnel --> cette fois, on ne module plus par le type de rubrique.\n",
    "df['modele_decisionnel_indicators_count'] = df['modele_decisionnel_maitrise_extanded'].reset_index().groupby(['modele_decisionnel_id']).agg({\n",
    "    'id' : pd.Series.nunique,\n",
    "    'levier_count' : 'sum',\n",
    "    'categorie_objectif' : pd.Series.nunique\n",
    "}).rename(columns={'id' : 'rubrique_count', 'categorie_objectif' : 'categorie_objectif_count'}).fillna(0)\n",
    "\n",
    "# fusion des informations obtenues au sein d'un même dataframe avant ajout à la table principale \n",
    "left = df['modele_decisionnel_indicators_count']\n",
    "right = df['modele_decisionnel_type_rubrique_count']\n",
    "df['modele_decisionnel_indicators_count'] = pd.merge(left, right, left_index=True, right_index=True, how='left').rename(columns=DICT_RENOMMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire remonter l'information jusqu'au modele_decisionnel\n",
    "left = df['modele_decisionnel']\n",
    "right = df['modele_decisionnel_indicators_count']\n",
    "df['modele_decisionnel_extanded'] = pd.merge(left, right, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# on complète les indicateurs pour les lignes qui étaient absentes jusqu'à maintenant\n",
    "indicators_to_fill = ['rubrique_count', 'levier_count', 'categorie_objectif_count'] + list(DICT_RENOMMAGE.values()) \n",
    "\n",
    "df['modele_decisionnel_extanded'][indicators_to_fill] =df['modele_decisionnel_extanded'][indicators_to_fill].fillna(0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on obtient un lot de variable qui viennent directement qualifier nos modèles décisionnels !\n",
    "df['modele_decisionnel_extanded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution de sdc_extanded\n",
    "- ajout de la variable have_OBSERVED\n",
    "- ajout de la variable have_PLANNED\n",
    "- ajout de la variable have_OBSERVED_or_PLANNED\n",
    "\n",
    "TODO : ajout de toutes les informations précédentes --> simples agrégations comme vu précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on qualifie les données plus précisément pour la suite\n",
    "df['modele_decisionnel_extanded'].loc[:, 'is_OBSERVED'] = df['modele_decisionnel_extanded']['categorie'] == 'OBSERVED'\n",
    "df['modele_decisionnel_extanded'].loc[:, 'is_PLANNED'] = df['modele_decisionnel_extanded']['categorie'] == 'PLANNED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on obtient si il y a bien un modèle décisionnel de chaque type dans le sdc en groupant et en vérifiant qu'au moins un MD du type est True \n",
    "# NOTE : c'est ce que permet de faire \"any\", si on exigeait qu'ils soient tous à true, on mettrait \"all\"\n",
    "\n",
    "df['modele_decisionnel_indicators'] = df['modele_decisionnel_extanded'].groupby('sdc_id').agg({\n",
    "    'is_OBSERVED' : any,\n",
    "    'is_PLANNED' : any\n",
    "}).rename(columns={'is_OBSERVED' : 'have_OBSERVED', 'is_PLANNED' : 'have_PLANNED'})\n",
    "\n",
    "df['modele_decisionnel_indicators'].loc[:, 'have_OBSERVED_or_PLANNED'] = df['modele_decisionnel_indicators']['have_OBSERVED'] | df['modele_decisionnel_indicators']['have_PLANNED']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrosyst_entrepot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
