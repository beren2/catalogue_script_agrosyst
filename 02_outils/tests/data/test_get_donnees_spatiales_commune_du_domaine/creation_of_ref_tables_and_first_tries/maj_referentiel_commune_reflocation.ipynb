{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scripts.interoperabilite as intop\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, URL\n",
    "from getpass import getpass\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psw = getpass(\"tbadie's password\")\n",
    "# psw = psw.replace('@', '%40')\n",
    "\n",
    "url_agsdev_agsprodcopy = URL.create(\n",
    "    \"postgresql+psycopg2\",\n",
    "    username = \"tbadie\",\n",
    "    password = psw,\n",
    "    host = \"147.100.179.208\",\n",
    "    port = '5438',\n",
    "    database = \"entrepot_20240923\",\n",
    ")\n",
    "del(psw)\n",
    "\n",
    "connection = create_engine(url_agsdev_agsprodcopy)\n",
    "\n",
    "refloc = pd.read_sql(\"SELECT codeinsee, topiaid FROM reflocation\", connection)\n",
    "refloc = refloc.rename(columns={'codeinsee':'CODGEO_2013'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = '/home/administrateur/Bureau/Datagrosyst/data_entrepot_&_outils/referentiels/geospatial_data/insee/'\n",
    "\n",
    "mig = pd.read_excel(path_csv+'ref_passage_INSEE.xlsx', dtype='str')\n",
    "mig = mig[['CODGEO_2024',\n",
    "           'LIBGEO_2024',\n",
    "           'CODGEO_2022',\n",
    "           'CODGEO_2017',\n",
    "           'CODGEO_2014',\n",
    "           'CODGEO_2013']]\n",
    "mig['CODGEO_2024'] = mig['CODGEO_2024'].str.rjust(5, '0')\n",
    "mig['CODGEO_2022'] = mig['CODGEO_2022'].str.rjust(5, '0')\n",
    "mig['CODGEO_2017'] = mig['CODGEO_2017'].str.rjust(5, '0')\n",
    "mig['CODGEO_2013'] = mig['CODGEO_2013'].str.rjust(5, '0')\n",
    "mig['CODGEO_2014'] = mig['CODGEO_2014'].str.rjust(5, '0')\n",
    "mig = mig.replace('00000', None)\n",
    "\n",
    "geo_DG = pd.read_csv(path_csv+'referentiel_geographique_fr_esr_unique.csv', encoding='latin1', dtype='str')\n",
    "geo_DG = geo_DG[['Municipality_code','Vineyard_basin','Region_old']].rename(columns={'Municipality_code' : 'CODGEO_2022'})\n",
    "geo_DG['CODGEO_2022'] = geo_DG['CODGEO_2022'].fillna('ZZZZZ')\n",
    "\n",
    "# latlon = pd.read_csv(path_csv+'lat_long.csv', dtype='str')\n",
    "# latlon['code_commune_INSEE'] = latlon['code_commune_INSEE'].str.rjust(5, '0')\n",
    "# latlon['code_departement'] = latlon['code_departement'].str.rjust(2, '0')\n",
    "# latlon = latlon.loc[~latlon['code_commune_INSEE'].duplicated() & latlon['latitude'].notna()]\n",
    "# latlon = latlon[latlon.columns.difference(['nom_commune_complet'])].rename(columns={'code_commune_INSEE' : 'CODGEO_2024'})\n",
    "\n",
    "# zipcode = pd.read_csv(path_csv+'zipcode.csv', encoding='latin1', dtype='str', sep=';')\n",
    "# zipcode = zipcode[['#Code_commune_INSEE','Code_postal']].rename(columns={'#Code_commune_INSEE' : 'CODGEO_2024', 'Code_postal' : 'codepostal'})\n",
    "# zipcode = zipcode.loc[~zipcode['CODGEO_2024'].duplicated() & zipcode['codepostal'].notna()]\n",
    "\n",
    "zipcode = pd.read_csv(path_csv+'zip lat lon geofla.csv', encoding='latin1', dtype='str', sep=';')\n",
    "zipcode = zipcode[['INSEE_COM','coordonnees_gps','Code_postal','ID_GEOFLA','Z_MOYEN','SUPERFICIE','POPULATION']]\n",
    "zipcode = zipcode.rename(columns={'INSEE_COM' : 'CODGEO_2014',\n",
    "                                  'coordonnees_gps' : 'gps',\n",
    "                                  'Code_postal' : 'codepostal',\n",
    "                                  'ID_GEOFLA' : 'GEOFLA2015_id',\n",
    "                                  'Z_MOYEN' : 'altitudemoy',\n",
    "                                  'SUPERFICIE' : 'area2015',\n",
    "                                  'POPULATION' : 'pop2015'})\n",
    "zipcode = zipcode.loc[~zipcode['CODGEO_2014'].duplicated()]\n",
    "\n",
    "pra = pd.read_excel(path_csv+'pra_vs_codeinsee.xls', dtype='str')\n",
    "pra = pra[['CODGEO','PRA_Code','PRA_Lib']].rename(columns={'CODGEO' : 'CODGEO_2017'})\n",
    "\n",
    "comm24 = pd.read_excel(path_csv+'commune_et_plus_2024.xlsx', dtype='str')\n",
    "comm24 = comm24[comm24.columns.difference(['commune_nom'])].rename(columns={'codeinsee' : 'CODGEO_2024'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mig))\n",
    "df = mig.merge(refloc, on='CODGEO_2013', how='outer') #+0\n",
    "print(len(df))\n",
    "df = df.merge(comm24, on='CODGEO_2024',  how='outer') #+0\n",
    "print(len(df))\n",
    "# df = df.merge(latlon, on='CODGEO_2024', how='outer') #+950\n",
    "# print(len(df))\n",
    "# df = df.merge(zipcode, on='CODGEO_2024', how='outer') #+90\n",
    "# print(len(df))\n",
    "df = df.merge(zipcode, on='CODGEO_2014', how='outer') #+1\n",
    "print(len(df))\n",
    "df = df.merge(pra, on='CODGEO_2017', how='outer') #+0\n",
    "print(len(df))\n",
    "df = df.merge(geo_DG, on='CODGEO_2022', how='outer') #+0\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on enleve les deux lignes entierement NA\n",
    "df = df.loc[~df.CODGEO_2024.isna()]\n",
    "df = df.loc[~df.duplicated()]\n",
    "df['topiaversion'] = '1'\n",
    "df['topiacreatedate'] = '20250106'\n",
    "df['timestamp'] = 'xxxx'\n",
    "df['active'] = '1'\n",
    "df['refcountry'] = 'fr.inra.agrosyst.api.entities.referential.RefCountry_454036f3-ecf2-472c-9158-b24e60bb24d1'\n",
    "\n",
    "df = df[['topiaid',\n",
    "        'topiaversion',\n",
    "        'CODGEO_2024',\n",
    "        'timestamp',\n",
    "        'LIBGEO_2024',\n",
    "        'PRA_Code', \n",
    "        'PRA_Lib',\n",
    "        'dep_code',\n",
    "        'codepostal',\n",
    "        'reg_code',\n",
    "        'active',\n",
    "        'gps',\n",
    "        'refcountry',\n",
    "        # +\n",
    "        'altitudemoy', \n",
    "        'area2015', \n",
    "        'pop2015', \n",
    "        'aire_attr_2020', \n",
    "        'arr_code',\n",
    "        'bassin_vie_2022',\n",
    "        'intercomm_code', \n",
    "        'unit_urb_2020', \n",
    "        'z_emploi_2020',\n",
    "        'GEOFLA2015_id',\n",
    "        'Vineyard_basin', \n",
    "        'Region_old',\n",
    "        'CODGEO_2022',\n",
    "        'CODGEO_2017', \n",
    "        'CODGEO_2014',\n",
    "        'CODGEO_2013']]\n",
    "\n",
    "# def alt_moy(x):\n",
    "#    a = fdf.loc[x.index]\n",
    "#    f = 0\n",
    "#    for idx, alt in enumerate(a['altitudemoy']):\n",
    "#      f = f + (alt * (a[idx]['area2015'] / sum(a['area2015'])))\n",
    "#    return f\n",
    "\n",
    "# okdf = df.loc[~(df.CODGEO_2024.duplicated(keep = False) | df.topiaid.duplicated(keep = False))]\n",
    "# caredf = df.loc[df.topiaid.duplicated(keep = False)]\n",
    "# fdf = df.loc[df.CODGEO_2024.duplicated(keep = False)].astype\n",
    "\n",
    "fdf = df.groupby(['CODGEO_2024','LIBGEO_2024'],as_index=False).aggregate({\n",
    "    'topiaid' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'topiaversion' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'timestamp': lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'PRA_Code' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'PRA_Lib' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'dep_code' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'codepostal' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'reg_code' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'active' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'gps' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'refcountry' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    # +\n",
    "    'altitudemoy' : lambda x: np.nan if all(x.isna()) else np.ceil(x.astype('Int64').mean()).astype(int), \n",
    "    'area2015' : lambda x: x.astype('Int64').sum(), \n",
    "    'pop2015' : lambda x: x.astype('Int64').sum(),\n",
    "    'aire_attr_2020' : lambda x: x.sort_values(na_position='last').iloc[0], \n",
    "    'arr_code' : lambda x: x.sort_values(na_position='last').iloc[0],\n",
    "    'bassin_vie_2022' : lambda x: x.sort_values(na_position='last').iloc[0], \n",
    "    'intercomm_code' : lambda x: x.sort_values(na_position='last').iloc[0], \n",
    "    'unit_urb_2020' : lambda x: x.sort_values(na_position='last').iloc[0], \n",
    "    'z_emploi_2020' : lambda x: x.sort_values(na_position='last').iloc[0],\n",
    "    'GEOFLA2015_id' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0], \n",
    "    'Vineyard_basin' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0], \n",
    "    'Region_old' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'CODGEO_2022' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'CODGEO_2017' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'CODGEO_2014' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    'CODGEO_2013' : lambda x: list(set(x.dropna())) if len(set(x.dropna())) > 1 else x.sort_values(na_position='last').iloc[0],\n",
    "    })\n",
    "\n",
    "# fdf.to_csv(path_csv + 'refloc_v3.csv', index=False)\n",
    "# caredf.to_csv(path_csv + 'refloc_duplic.csv', index=False)\n",
    "# okdf.to_csv(path_csv + 'refloc_ok.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = fdf\n",
    "fdff['temp_checking'] = np.where(fdff['topiaid'].str.contains('\\['), 'fusion', 'un_pour_un')\n",
    "fdff.loc[fdff.topiaid.duplicated(keep = False),'temp_checking'] = 'scission'\n",
    "\n",
    "check1 = fdff.loc[fdff.PRA_Code.str.contains('\\[', na=True), ['CODGEO_2024','LIBGEO_2024','PRA_Code','PRA_Lib','temp_checking']]\n",
    "check2 = fdff.loc[fdff.gps.str.contains('\\[', na=True), ['CODGEO_2024','LIBGEO_2024','gps','temp_checking']]\n",
    "\n",
    "update = pd.read_csv(path_csv+'refloc_check_v1.csv', dtype='str')\n",
    "fdff = fdff.merge(update.loc[update.CODGEO_2024.isin(list(check1.CODGEO_2024)),['CODGEO_2024','PRA_Code','PRA_Lib']], on='CODGEO_2024', how='left', suffixes=('', '_new'))\n",
    "fdff['PRA_Code'] = np.where(pd.notnull(fdff['PRA_Code_new']), fdff['PRA_Code_new'], fdff['PRA_Code'])\n",
    "fdff['PRA_Lib'] = np.where(pd.notnull(fdff['PRA_Lib_new']), fdff['PRA_Lib_new'], fdff['PRA_Lib'])\n",
    "fdff.drop('PRA_Code_new', axis=1, inplace=True)\n",
    "fdff.drop('PRA_Lib_new', axis=1, inplace=True)\n",
    "\n",
    "fdff = fdff.merge(update.loc[update.CODGEO_2024.isin(list(check2.CODGEO_2024)), ['CODGEO_2024','gps']], on='CODGEO_2024', how='left', suffixes=('', '_new'))\n",
    "fdff['gps'] = np.where(pd.notnull(fdff['gps_new']), fdff['gps_new'], fdff['gps'])\n",
    "fdff.drop('gps_new', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff.loc[fdff.codepostal.str.contains('\\[', na=True), ['CODGEO_2024','LIBGEO_2024','codepostal','temp_checking']]\n",
    "\n",
    "fdff.loc[fdff.CODGEO_2024 == '13055', 'codepostal'] = '13000'\n",
    "fdff.loc[fdff.CODGEO_2024 == '18173', 'codepostal'] = '18130'\n",
    "fdff.loc[fdff.CODGEO_2024 == '51457', 'codepostal'] = '51480'\n",
    "fdff.loc[fdff.CODGEO_2024 == '60694', 'codepostal'] = '60390'\n",
    "fdff.loc[fdff.CODGEO_2024 == '64300', 'codepostal'] = '64170'\n",
    "fdff.loc[fdff.CODGEO_2024 == '69123', 'codepostal'] = '69000'\n",
    "fdff.loc[fdff.CODGEO_2024 == '69149', 'codepostal'] = '69310'\n",
    "fdff.loc[fdff.CODGEO_2024 == '75056', 'codepostal'] = '75000'\n",
    "fdff.loc[fdff.CODGEO_2024 == '85165', 'codepostal'] = '85140'\n",
    "fdff.loc[fdff.CODGEO_2024 == '85212', 'codepostal'] = '85140'\n",
    "\n",
    "fdff.loc[fdff.CODGEO_2024 == '75056', ['area2015','pop2015','altitudemoy','gps']] = ['10534','2240621','35','48.866667, 2.333333']\n",
    "fdff.loc[fdff.CODGEO_2024 == '13055', ['area2015','pop2015','altitudemoy','gps']] = ['23851','852516','179','43.296482, 5.36978']\n",
    "fdff.loc[fdff.CODGEO_2024 == '69123', ['area2015','pop2015','altitudemoy','gps']] = ['4794','496343','237','45.764043, 4.835659']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = fdff.rename(columns={\n",
    "        'topiaid': 'ex_topiaid',\n",
    "        # -\n",
    "        # 'topiaversion',\n",
    "        'CODGEO_2024' : 'codeInsee',\n",
    "        # 'timestamp',\n",
    "        'LIBGEO_2024' : 'commune',\n",
    "        'PRA_Code': 'petiteRegionAgricoleCode', \n",
    "        'PRA_Lib' : 'petiteRegionAgricoleNom',\n",
    "        'dep_code' : 'departement',\n",
    "        'codepostal' : 'codePostal',\n",
    "        'reg_code' : 'region',\n",
    "        # 'active',\n",
    "        # 'gps',\n",
    "        # 'refcountry',\n",
    "        # +\n",
    "        'altitudemoy' : 'altitudeMoyenne', \n",
    "        'area2015' : 'aire_ha_2015', \n",
    "        'pop2015' : 'pop_2015', \n",
    "        'aire_attr_2020': 'aireAttraction', \n",
    "        'arr_code' : 'arrondissementCode',\n",
    "        'bassin_vie_2022': 'bassinVie',\n",
    "        'intercomm_code' : 'intercommunaliteCode', \n",
    "        'unit_urb_2020' : 'uniteUrbaine', \n",
    "        'z_emploi_2020' : 'zoneEmploi',\n",
    "        # 'GEOFLA2015_id',\n",
    "        'Vineyard_basin' : 'bassinViticole', \n",
    "        'Region_old' : 'regionPre2016',\n",
    "        'CODGEO_2022' : 'code_insee_2022',\n",
    "        'CODGEO_2017' : 'code_insee_2017',\n",
    "        'CODGEO_2014' : 'code_insee_2014',\n",
    "        'CODGEO_2013' : 'code_insee_2013'\n",
    "})\n",
    "\n",
    "fdff[['latitude', 'longitude']] = fdff['gps'].str.split(', ', n=1, expand=True)\n",
    "fdff['pays'] = 'fra'\n",
    "fdff['active'] = 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = fdff[['codeInsee', \n",
    "             'commune', \n",
    "             'region', \n",
    "             'departement',\n",
    "             'codePostal', \n",
    "            #  'topiaversion', \n",
    "            #  'timestamp',\n",
    "             'petiteRegionAgricoleCode',\n",
    "             'petiteRegionAgricoleNom',\n",
    "             'pays',\n",
    "             'latitude', \n",
    "             'longitude', \n",
    "             'altitudeMoyenne',\n",
    "             'aireAttraction',\n",
    "             'arrondissementCode',\n",
    "             'bassinVie',\n",
    "             'intercommunaliteCode',\n",
    "             'uniteUrbaine',\n",
    "             'zoneEmploi',\n",
    "             'bassinViticole',\n",
    "             'regionPre2016',\n",
    "             'active',\n",
    "            #  'refcountry', \n",
    "            #  'aire_ha_2015', \n",
    "            #  'pop_2015', \n",
    "             'GEOFLA2015_id',\n",
    "            #  'code_insee_2022', \n",
    "            #  'code_insee_2017',\n",
    "            #  'code_insee_2014', \n",
    "            #  'code_insee_2013',\n",
    "             'temp_checking',\n",
    "             'ex_topiaid']]\n",
    "\n",
    "fdff.to_csv(path_csv + 'maj_reflocation_ticket13305.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit('Attention deux parties de script. La suivante est faite pour créer le script de migration !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scripts.interoperabilite as intop\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, URL\n",
    "from getpass import getpass\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psw = getpass(\"tbadie's password\")\n",
    "# # psw = psw.replace('@', '%40')\n",
    "\n",
    "# url_agsdev_agsprodcopy = URL.create(\n",
    "#     \"postgresql+psycopg2\",\n",
    "#     username = \"tbadie\",\n",
    "#     password = psw,\n",
    "#     host = \"147.100.179.208\",\n",
    "#     port = '5438',\n",
    "#     database = \"agrosyst_13167_20250130\",\n",
    "# )\n",
    "# del(psw)\n",
    "\n",
    "# connection = create_engine(url_agsdev_agsprodcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ARRIVEE DE LA 3.6 \n",
    "\n",
    "path = '/home/administrateur/Bureau/Datagrosyst/data_entrepot_&_outils/referentiels/geospatial_data/insee/'\n",
    "df_refcomm = pd.read_csv(path + 'reflocation_3_6.csv', sep=';', low_memory=False)\n",
    "df_refcomm = df_refcomm[['topiaid','codeinsee']]\n",
    "# maj_other_ref = fdff.loc[(fdff['temp_checking']=='fusion') & (fdff['ex_topiaid'].str.contains('\\[', na=True)), ['codeinsee','ex_topiaid']] \n",
    "maj_other_ref = pd.read_csv(path + 'maj_reflocation_ticket13305.csv', sep=';', low_memory=False)\n",
    "# double précaution mais on devrait juste se baser sur temp_cheking\n",
    "maj_other_ref = maj_other_ref.loc[(maj_other_ref['temp_checking']=='fusion') & (maj_other_ref['ex_topiaid'].str.contains('\\[', na=True)), ['codeinsee','ex_topiaid']]\n",
    "\n",
    "maj_other_ref['ex_topiaid'] = maj_other_ref['ex_topiaid'].apply(literal_eval)\n",
    "maj_other_ref = maj_other_ref.explode('ex_topiaid')\n",
    "\n",
    "ref = maj_other_ref.merge(df_refcomm, on = 'codeinsee', how='left')\n",
    "ref = ref.loc[ref['ex_topiaid'] != ref['topiaid']]\n",
    "# ref = ref[['ex_topiaid','topiaid']]\n",
    "\n",
    "tables = ['practicedplot','plot','domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.to_csv(path + 'refcommune_fusionnee.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = []\n",
    "for id, row in ref.iterrows() :\n",
    "    for t in tables :\n",
    "        sql.append('UPDATE public.'+ t +' SET location = \\'' + str(row['topiaid']) + '\\' WHERE location = \\''+ str(row['ex_topiaid']) + '\\' ;')\n",
    "    sql.append('UPDATE public.reflocation SET active = false WHERE topiaid = \\'' + row['ex_topiaid'] + '\\' ;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"script_migration_reflocation.txt\", \"w\") as output:\n",
    "    output.write(str(sql))\n",
    "\n",
    "# sql_refloc = pd.DataFrame({'reflocation_edit_active': [sql_refloc]})\n",
    "# sql = pd.DataFrame({'other_table_edit_location_id': [sql]})\n",
    "# sql_refloc.to_sql('reflocation_edit_active.sql', connection)\n",
    "# sql.to_sql('other_table_edit_location_id.sql', connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogue_script_agrosyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
